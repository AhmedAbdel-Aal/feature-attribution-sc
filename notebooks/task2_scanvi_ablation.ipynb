{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "706ea6f7",
   "metadata": {},
   "source": [
    "Inspired by the implementation proposed in Fisher, Rudin, Dominici (2018) https://arxiv.org/abs/1801.01489"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ee8606",
   "metadata": {},
   "source": [
    "import modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cabfa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scvi\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scvi import REGISTRY_KEYS\n",
    "from captum.attr import FeatureAblation\n",
    "\n",
    "sc.set_figure_params(dpi=100, frameon=False, color_map='Reds', facecolor=None)\n",
    "sc.logging.print_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc40139",
   "metadata": {},
   "source": [
    "## load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aace4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/icb/yuge.ji/projects/feature-attribution-sc'\n",
    "hlca_path = f'{base_path}/datasets/hlca_subset.h5ad'\n",
    "adata = sc.read(hlca_path)\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81716532",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = scvi.model.SCANVI.load('/home/icb/yuge.ji/projects/HLCA_reproducibility/notebooks/3_atlas_extension/scanvi_model/', adata)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6292c2f2",
   "metadata": {},
   "source": [
    "get cell type names that match the labels (integers in the model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8489a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_names = model.adata_manager.get_state_registry(REGISTRY_KEYS.LABELS_KEY)['categorical_mapping']\n",
    "ct_names = [ct for ct in ct_names if ct != \"unlabeled\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0579e2c9",
   "metadata": {},
   "source": [
    "define batch size. In this case we'll set it to the entire size of the subsetted HLCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da20d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=adata.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78cf8cd",
   "metadata": {},
   "source": [
    "create a dataloader and load your first batch (in this case all the cells):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d05ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "scdl = model._make_data_loader(adata=adata, indices=list(range(adata.shape[0])), batch_size=batch_size)\n",
    "batch = next(scdl.__iter__())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543fae50",
   "metadata": {},
   "source": [
    "### measure against posterior (not done yet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c269cf8",
   "metadata": {},
   "source": [
    "Wrap `model.module.forward` because captum has an internal check that the inputs pass are tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46afd685",
   "metadata": {},
   "source": [
    "Captum returns an attribution map of either `tensor(n_features * output_size, n_features), n_inputs` or ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c281fe3",
   "metadata": {},
   "source": [
    "### Measure feature attribution with respect to classification probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6f9e22",
   "metadata": {},
   "source": [
    "create the ablator, containing the forward function inside of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426a3fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ablator = FeatureAblation(model.module.classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf562a8",
   "metadata": {},
   "source": [
    "Run the feature attribution function. The attribution below outputs two tensors. One ablates the gene features one by one, for every cell, and has shape (n_cells * n_ct_classes) * n_genes. The other ablates the (biological) batch variable, which it takes as a single, continuous variable (even though it is a one-hot encoded (n_datasets)-dimensional variable), and therefore ablates it once per cell, and outputs a (n_cells * n_ct_classes) * 1 shape tensor. We'll ignore that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12219a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# per feature per output\n",
    "attribution_map = ablator.attribute((batch['X'], batch['batch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d002437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# per feature per output\n",
    "attribution_map = ablator.attribute((batch['X'], batch['batch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribution_map_genes = attribution_map[0] # take only the first tensor (explained above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfc8787",
   "metadata": {},
   "source": [
    "reshape, such that n_cells\\*n_classes is split into two dimensions ((n_cells*28) becomes n_cells*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe8db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribution_map_genes_3d = attribution_map_genes.reshape((batch_size,28,2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3129c6",
   "metadata": {},
   "source": [
    "For each class, calculate mean only across cells of that class (= cell type), ignore other cells. Then take only the feature importances for that particular class. Reasoning: we want to learn which features were important for classifing a cell of cell type a *as* cell type a, and not the features that made the model *not* classify it as cell type a (the latter would give negative markers rather than positive ones). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0186d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = pd.DataFrame(index=adata.var_names,columns=ct_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ef922",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ct in batch['labels'].unique():\n",
    "    ct_float = ct.item()\n",
    "    ct_int = int(ct_float)\n",
    "    ct_indexing = (batch['labels'] == ct_float).reshape(-1)\n",
    "    means.iloc[:,ct_int] = torch.mean(attribution_map_genes_3d[ct_indexing,ct_int,:],dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae5d695",
   "metadata": {},
   "source": [
    "### measure against latent (to do)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e272bbe",
   "metadata": {},
   "source": [
    "## Store results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a12fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "means.to_csv(\"../outputs/ablation/task2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e433bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
